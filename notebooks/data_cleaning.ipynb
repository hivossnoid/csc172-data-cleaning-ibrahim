{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1070b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "clean_data_pipeline.py\n",
    "A functional pipeline demonstrating data-cleaning steps.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e48a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44abc2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Data Creation\n",
    "# ---------------------------------------------------------\n",
    "def create_raw_data() -> pd.DataFrame:\n",
    "    raw_data = {\n",
    "        \"CustomerID\": [1, 2, 2, 3, 4, 5, 6, 7],\n",
    "        \"Name\": [\"Alice\", \"Bob\", \"bob\", \"Charlie\", None, \"Eve\", \"Frank\", \"Grace\"],\n",
    "        \"Age\": [25, 30, np.nan, 40, 200, 22, 28, None],\n",
    "        \"SignupDate\": [\"2024-01-01\", \"01/15/2024\", \"01/15/2024\", \"2024-02-20\",\n",
    "                       \"2024-02-30\", \"2024-03-05\", None, \"2024-03-15\"],\n",
    "        \"City\": [\"NY\", \"nyc\", \"NYC\", \"New York\", \"LA\", \"Los Angeles\", \"LA \", \" SF\"],\n",
    "        \"Income\": [50000, 60000, 60000, 80000, 1200000, 45000, None, 70000],\n",
    "        \"Purchased\": [\"Yes\", \"No\", \"no\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\"]\n",
    "    }\n",
    "    return pd.DataFrame(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Cleaning Functions\n",
    "# ---------------------------------------------------------\n",
    "def handle_missing(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"Age\"].fillna(df[\"Age\"].median(), inplace=True)\n",
    "    df[\"Income\"].fillna(df[\"Income\"].mean(), inplace=True)\n",
    "    df[\"Name\"].fillna(\"Unknown\", inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d3c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_types(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"SignupDate\"] = pd.to_datetime(df[\"SignupDate\"], errors=\"coerce\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d953a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe9b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_strings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"Name\"] = df[\"Name\"].str.title()\n",
    "    df[\"City\"] = df[\"City\"].str.strip().str.lower()\n",
    "    city_map = {\n",
    "        \"ny\": \"New York\", \"nyc\": \"New York\", \"new york\": \"New York\",\n",
    "        \"la\": \"Los Angeles\", \"los angeles\": \"Los Angeles\", \"sf\": \"San Francisco\"\n",
    "    }\n",
    "    df[\"City\"] = df[\"City\"].replace(city_map)\n",
    "    df[\"Purchased\"] = df[\"Purchased\"].str.lower().map({\"yes\": 1, \"no\": 0})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Cap unreasonable ages\n",
    "    df.loc[df[\"Age\"] > 100, \"Age\"] = df[\"Age\"].median()\n",
    "    # Cap extreme incomes at 99th percentile\n",
    "    upper_cap = df[\"Income\"].quantile(0.99)\n",
    "    df[\"Income\"] = np.where(df[\"Income\"] > upper_cap, upper_cap, df[\"Income\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2178a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    today = pd.Timestamp(\"2025-09-28\")\n",
    "    df[\"DaysSinceSignup\"] = (today - df[\"SignupDate\"]).dt.days\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164458f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Preprocessing Pipeline for Modeling\n",
    "# ---------------------------------------------------------\n",
    "def build_preprocessor(numeric_features, categorical_features) -> ColumnTransformer:\n",
    "    numeric_transformer = Pipeline([(\"scaler\", StandardScaler())])\n",
    "    categorical_transformer = Pipeline([(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "    return ColumnTransformer([\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ce3332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Main Cleaning Orchestrator\n",
    "# ---------------------------------------------------------\n",
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = handle_missing(df)\n",
    "    df = correct_types(df)\n",
    "    df = remove_duplicates(df)\n",
    "    df = standardize_strings(df)\n",
    "    df = handle_outliers(df)\n",
    "    df = engineer_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Demo Execution\n",
    "# ---------------------------------------------------------\n",
    "def main():\n",
    "    df = create_raw_data()\n",
    "    print(\"\\n==== RAW DATA ====\")\n",
    "    print(df)\n",
    "\n",
    "    df_clean = clean_data(df)\n",
    "    print(\"\\n==== CLEANED DATA ====\")\n",
    "    print(df_clean)\n",
    "\n",
    "    # Example: prepping for modeling\n",
    "    X = df_clean.drop(columns=[\"Purchased\", \"CustomerID\", \"Name\", \"SignupDate\"])\n",
    "    y = df_clean[\"Purchased\"]\n",
    "\n",
    "    numeric_features = [\"Age\", \"Income\", \"DaysSinceSignup\"]\n",
    "    categorical_features = [\"City\"]\n",
    "\n",
    "    preprocessor = build_preprocessor(numeric_features, categorical_features)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train_ready = preprocessor.fit_transform(X_train)\n",
    "\n",
    "    print(\"\\nTransformed training set shape:\", X_train_ready.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685277fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
